{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Model building.     "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25ba1c7c9df917ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-03T12:53:06.631840Z",
     "start_time": "2024-10-03T12:53:06.508968Z"
    }
   },
   "id": "initial_id",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1989 images belonging to 2 classes.\n",
      "Found 1599 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,                                            # Normalization\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)                 # We only want to generate the data from training dataset not from the validation. For training we are making changes in the train dataset. We don't need to do any changes on test data. \n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/valid',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T12:57:00.126486Z",
     "start_time": "2024-10-03T12:56:59.957808Z"
    }
   },
   "id": "665c109203e3cc58",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "124/124 [==============================] - 15s 123ms/step - loss: 0.5484 - accuracy: 0.7202 - val_loss: 0.8427 - val_accuracy: 0.6458\n",
      "Epoch 2/5\n",
      "124/124 [==============================] - 15s 118ms/step - loss: 0.5295 - accuracy: 0.7466 - val_loss: 0.6230 - val_accuracy: 0.7090\n",
      "Epoch 3/5\n",
      "124/124 [==============================] - 14s 111ms/step - loss: 0.5295 - accuracy: 0.7278 - val_loss: 0.5488 - val_accuracy: 0.7418\n",
      "Epoch 4/5\n",
      "124/124 [==============================] - 14s 114ms/step - loss: 0.5130 - accuracy: 0.7643 - val_loss: 0.5212 - val_accuracy: 0.7664\n",
      "Epoch 5/5\n",
      "124/124 [==============================] - 16s 131ms/step - loss: 0.4876 - accuracy: 0.7795 - val_loss: 0.5863 - val_accuracy: 0.7165\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1989 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1599 // batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T13:02:26.805438Z",
     "start_time": "2024-10-03T13:01:12.343411Z"
    }
   },
   "id": "56ef76ce60399e36",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
