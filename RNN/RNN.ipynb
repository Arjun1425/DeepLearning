{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Converting text into vector using integer encoding and using simpleRNN. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1736452cb6e09056"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "docs = ['go india',\n",
    "\t\t'india india',\n",
    "\t\t'hip hip hurray',\n",
    "\t\t'jeetega bhai jeetega india jeetega',\n",
    "\t\t'bharat mata ki jai',\n",
    "\t\t'kohli kohli',\n",
    "\t\t'sachin sachin',\n",
    "\t\t'dhoni dhoni',\n",
    "\t\t'modi ji ki jai',\n",
    "\t\t'inquilab zindabad']"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.018331Z",
     "start_time": "2024-10-15T12:09:49.005391Z"
    }
   },
   "id": "initial_id",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer       # we do tokenization to convert text into words. Changing capital letters to small letters. Remove stop words, special symbols. \n",
    "\n",
    "tokenizer =Tokenizer(oov_token='Arjun')  # Here you are replacing any word in the test dataset which is not present in the training dataset with 'Arjun'. oov = out of vocab token."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.034265Z",
     "start_time": "2024-10-15T12:09:49.029427Z"
    }
   },
   "id": "eb3525a48b7bcdff",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.052135Z",
     "start_time": "2024-10-15T12:09:49.049298Z"
    }
   },
   "id": "7f9bc16fa471efdb",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Arjun': 1,\n 'india': 2,\n 'jeetega': 3,\n 'hip': 4,\n 'ki': 5,\n 'jai': 6,\n 'kohli': 7,\n 'sachin': 8,\n 'dhoni': 9,\n 'go': 10,\n 'hurray': 11,\n 'bhai': 12,\n 'bharat': 13,\n 'mata': 14,\n 'modi': 15,\n 'ji': 16,\n 'inquilab': 17,\n 'zindabad': 18}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the assigned index of the words in the vocab corpus. \n",
    "tokenizer.word_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.058800Z",
     "start_time": "2024-10-15T12:09:49.053328Z"
    }
   },
   "id": "fc49377e94a57b43",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('go', 1),\n             ('india', 4),\n             ('hip', 2),\n             ('hurray', 1),\n             ('jeetega', 3),\n             ('bhai', 1),\n             ('bharat', 1),\n             ('mata', 1),\n             ('ki', 2),\n             ('jai', 2),\n             ('kohli', 2),\n             ('sachin', 2),\n             ('dhoni', 2),\n             ('modi', 1),\n             ('ji', 1),\n             ('inquilab', 1),\n             ('zindabad', 1)])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the frequency of the words in the vocab. \n",
    "tokenizer.word_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.064719Z",
     "start_time": "2024-10-15T12:09:49.060971Z"
    }
   },
   "id": "8e35526547a2874c",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the number of rows in the document. \n",
    "tokenizer.document_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.069006Z",
     "start_time": "2024-10-15T12:09:49.066101Z"
    }
   },
   "id": "18a51a7f8f144d9c",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 2], [2, 2], [4, 4, 11], [3, 12, 3, 2, 3], [13, 14, 5, 6], [7, 7], [8, 8], [9, 9], [15, 16, 5, 6], [17, 18]]\n"
     ]
    }
   ],
   "source": [
    "# Converting words to sequence. \n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "print(sequences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.072439Z",
     "start_time": "2024-10-15T12:09:49.070296Z"
    }
   },
   "id": "af40f44118f62084",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  2  0  0  0]\n",
      " [ 2  2  0  0  0]\n",
      " [ 4  4 11  0  0]\n",
      " [ 3 12  3  2  3]\n",
      " [13 14  5  6  0]\n",
      " [ 7  7  0  0  0]\n",
      " [ 8  8  0  0  0]\n",
      " [ 9  9  0  0  0]\n",
      " [15 16  5  6  0]\n",
      " [17 18  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Adding padding to make size of all sequences equal. \n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "sequences = pad_sequences(sequences, padding='post')     # post means the zero will be at the end of the sequence. \n",
    "print(sequences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.076175Z",
     "start_time": "2024-10-15T12:09:49.073441Z"
    }
   },
   "id": "6a4274c9edef0588",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:49.088508Z",
     "start_time": "2024-10-15T12:09:49.085706Z"
    }
   },
   "id": "80314967b1690b0d",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:51.192491Z",
     "start_time": "2024-10-15T12:09:49.090425Z"
    }
   },
   "id": "7d87627c82fc76fa",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
     ]
    }
   ],
   "source": [
    "# Already preprocessed data with integer encoding. \n",
    "print(x_train[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:51.195593Z",
     "start_time": "2024-10-15T12:09:51.193663Z"
    }
   },
   "id": "126fcb938b898252",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# To make the dataset of similar size I am using padding here and also trimming the data so, it will train fast. \n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=50, padding='post')\n",
    "x_test = pad_sequences(x_test, maxlen=50, padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:51.385167Z",
     "start_time": "2024-10-15T12:09:51.196304Z"
    }
   },
   "id": "a2f9ccd7e26f7435",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8255     5 25249   656   245  2350     5     4  9837   131   152   491\n",
      "    18 46151    32  7464  1212    14     9     6   371    78    22   625\n",
      "    64  1382     9     8   168   145    23     4  1690    15    16     4\n",
      "  1355     5    28     6    52   154   462    33    89    78   285    16\n",
      "   145    95]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:51.389045Z",
     "start_time": "2024-10-15T12:09:51.386839Z"
    }
   },
   "id": "4b25b1ec43456064",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 32)                1088      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1121 (4.38 KB)\n",
      "Trainable params: 1121 (4.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Making the model. \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(32, input_shape=(50,1), return_sequences=False))      # Here we have 50 time-steps same as the dimension of the dataset and sending 1 input feature at a time. The reason why we set return statement false because we don't want output at every time-step. We are doing sentiment analysis so no need of that. \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:09:51.441324Z",
     "start_time": "2024-10-15T12:09:51.390470Z"
    }
   },
   "id": "c859ef6b8e9492d5",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.6981 - accuracy: 0.5083 - val_loss: 0.6941 - val_accuracy: 0.5033\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.6934 - accuracy: 0.5014 - val_loss: 0.6938 - val_accuracy: 0.5044\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.6927 - accuracy: 0.5114 - val_loss: 0.6949 - val_accuracy: 0.5008\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.6930 - accuracy: 0.5049 - val_loss: 0.6938 - val_accuracy: 0.5055\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.6930 - accuracy: 0.5013 - val_loss: 0.6936 - val_accuracy: 0.5062\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x31824e250>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:10:04.647745Z",
     "start_time": "2024-10-15T12:09:51.442165Z"
    }
   },
   "id": "60eac684f28af008",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using embedding."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c58a48d25179914"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:12:15.399421Z",
     "start_time": "2024-10-15T12:12:15.393208Z"
    }
   },
   "id": "bfd3021f4373656c",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:12:16.795315Z",
     "start_time": "2024-10-15T12:12:16.789145Z"
    }
   },
   "id": "9291a300440c0eb3",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:12:18.172503Z",
     "start_time": "2024-10-15T12:12:18.165500Z"
    }
   },
   "id": "b87f3335aab6aeb",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[[9, 1],\n [1, 1],\n [3, 3, 10],\n [2, 11, 2, 1, 2],\n [12, 13, 4, 5],\n [6, 6],\n [7, 7],\n [8, 8],\n [14, 15, 4, 5],\n [16, 17]]"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:12:27.474248Z",
     "start_time": "2024-10-15T12:12:27.464626Z"
    }
   },
   "id": "75d4be19716bbf85",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  1  0  0  0]\n",
      " [ 1  1  0  0  0]\n",
      " [ 3  3 10  0  0]\n",
      " [ 2 11  2  1  2]\n",
      " [12 13  4  5  0]\n",
      " [ 6  6  0  0  0]\n",
      " [ 7  7  0  0  0]\n",
      " [ 8  8  0  0  0]\n",
      " [14 15  4  5  0]\n",
      " [16 17  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences,padding='post')\n",
    "print(sequences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:16:55.185179Z",
     "start_time": "2024-10-15T12:16:55.171341Z"
    }
   },
   "id": "15c53061ca8ac0dc",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 5, 2)              36        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36 (144.00 Byte)\n",
      "Trainable params: 36 (144.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(18,output_dim=2,input_length=5))      # Here you will have to increase the embedding dimension by 1 from 17 to 18 to include the \"unknown\" token.\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:15:04.573065Z",
     "start_time": "2024-10-15T12:15:04.524454Z"
    }
   },
   "id": "8a7360431c2cb457",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile('adam','accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:15:07.760145Z",
     "start_time": "2024-10-15T12:15:07.724323Z"
    }
   },
   "id": "a5cb1f2cf3f0dcc8",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[[-0.01510189 -0.01504215]\n",
      "  [ 0.04290788  0.01403778]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[ 0.04290788  0.01403778]\n",
      "  [ 0.04290788  0.01403778]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[ 0.03129901  0.00858117]\n",
      "  [ 0.03129901  0.00858117]\n",
      "  [ 0.03141688 -0.02979585]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[ 0.00856427 -0.01753614]\n",
      "  [-0.02623016 -0.0024384 ]\n",
      "  [ 0.00856427 -0.01753614]\n",
      "  [ 0.04290788  0.01403778]\n",
      "  [ 0.00856427 -0.01753614]]\n",
      "\n",
      " [[ 0.02463695 -0.02652116]\n",
      "  [-0.04525285 -0.04378453]\n",
      "  [-0.0203311  -0.03013411]\n",
      "  [-0.02868924 -0.03771811]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[-0.04188278 -0.03115167]\n",
      "  [-0.04188278 -0.03115167]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[ 0.00867699 -0.00260112]\n",
      "  [ 0.00867699 -0.00260112]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[ 0.04308089 -0.04439318]\n",
      "  [ 0.04308089 -0.04439318]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[ 0.02144221 -0.01556121]\n",
      "  [-0.04831218  0.02946487]\n",
      "  [-0.0203311  -0.03013411]\n",
      "  [-0.02868924 -0.03771811]\n",
      "  [ 0.00112004  0.01680036]]\n",
      "\n",
      " [[ 0.01784912 -0.03426557]\n",
      "  [ 0.04803519 -0.0226271 ]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]\n",
      "  [ 0.00112004  0.01680036]]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(sequences)\n",
    "print(pred)                       # Here every word is converted into 2 embedding outputs. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:15:10.426638Z",
     "start_time": "2024-10-15T12:15:10.339455Z"
    }
   },
   "id": "8dc851d7efdeb179",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:19:10.873475Z",
     "start_time": "2024-10-15T12:19:08.701545Z"
    }
   },
   "id": "d7ced2d005358034",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=50, padding='post')\n",
    "x_test = pad_sequences(x_test, maxlen=50, padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:19:11.825515Z",
     "start_time": "2024-10-15T12:19:11.623821Z"
    }
   },
   "id": "1b6b049b674fba8d",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(25000, 50)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:19:13.200001Z",
     "start_time": "2024-10-15T12:19:13.193015Z"
    }
   },
   "id": "7f4eddd5eb2a89e1",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 50, 2)             200000    \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, 32)                1120      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201153 (785.75 KB)\n",
      "Trainable params: 201153 (785.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Adding embedding. \n",
    "model.add(Embedding(100000, 2, input_length=50))    # Here I am changing every word in two words embedding. In this my input dimension is 10000, and it is going to 2 embedding nodes which is giving 2 outputs. \n",
    "model.add(SimpleRNN(32, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:19:16.177060Z",
     "start_time": "2024-10-15T12:19:16.105413Z"
    }
   },
   "id": "60c7d16f8730270f",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.6524 - accuracy: 0.5784 - val_loss: 0.4856 - val_accuracy: 0.7721\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4008 - accuracy: 0.8240 - val_loss: 0.4376 - val_accuracy: 0.7969\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2667 - accuracy: 0.8970 - val_loss: 0.4381 - val_accuracy: 0.8065\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1851 - accuracy: 0.9336 - val_loss: 0.5150 - val_accuracy: 0.7999\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1366 - accuracy: 0.9539 - val_loss: 0.5781 - val_accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,epochs=5,validation_data=(x_test,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T12:19:40.804772Z",
     "start_time": "2024-10-15T12:19:20.626519Z"
    }
   },
   "id": "f48b172e17a460ac",
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
